{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50bec8d6",
   "metadata": {},
   "source": [
    "# Machine Learning - Group Assignment 2\n",
    "\n",
    "- Ankita Kokkera - 06032419\n",
    "- Aria Wang - 06047688\n",
    "- Tsamara Esperanti Erwin - 06042275\n",
    "- Jean-Marc Yao - 06055972\n",
    "- Amer Mulla - 06027165"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e122ae51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from naive_bayes import NaiveBayesForSpam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae13653b",
   "metadata": {},
   "source": [
    "### 1. Load the data files and list files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2a65dfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pd.read_csv(\"training.txt\")\n",
    "validation = pd.read_csv(\"validation.txt\")\n",
    "test1 = pd.read_csv(\"test1.txt\")\n",
    "test2 = pd.read_csv(\"test2.txt\")\n",
    "\n",
    "with open(\"censored_list_test1.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    test1_list = f.read().splitlines()\n",
    "\n",
    "with open(\"censored_list_test2.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    test2_list = f.read().splitlines()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05bbb5b",
   "metadata": {},
   "source": [
    "### 2. Pre-process the SMS messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "84aad4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [training, validation, test1, test2]:\n",
    "    df[\"sms\"] = (\n",
    "        df[\"sms\"]\n",
    "          .str.lower()\n",
    "          .str.replace(r\"[0-9]\", \"\", regex=True)\n",
    "          .str.replace(r\"[^\\w\\s]\", \"\", regex=True)\n",
    "          .str.replace(r\"\\s+\", \" \", regex=True)\n",
    "          .str.strip()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23a9b6e",
   "metadata": {},
   "source": [
    "### 3. Review the provided Naïve Bayes code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e022fc6b",
   "metadata": {},
   "source": [
    "### 4. Explain the model functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e988945",
   "metadata": {},
   "source": [
    "**`train`**: fits the Naïve Bayes model using the full vocabulary from the training set by estimating the prior probabilities for ham and spam and the word likelihood probabilities for each class. It stores these parameters so that posterior probabilities can be computed later in `predict` for new messages.\n",
    "\n",
    "**`train2`**: fits a Naïve Bayes model by estimating the prior probabilities and word likelihood probabilities, but it applies feature selection by retaining only words that are at least 20 times more likely to appear in spam than in ham. It stores these filtered parameters so that posterior probabilities can be computed later in `predict` using a reduced set of spam indicative words.\n",
    "\n",
    "**Difference between `train` and `train2`**: The main difference between `train` and `train2` is feature selection and the resulting vocabulary size. `train` uses the full vocabulary from the training set, including many neutral or common words, whereas `train2` keeps only words that are much more likely to appear in spam than in ham, producing a smaller and more spam focused model.\n",
    "\n",
    "**`predict`**: applies Bayes’ Theorem under the Naïve Bayes independence assumption to compute the posterior probabilities of ham and spam for a given message. It then assigns the label with the higher posterior probability and returns that label with its probability.\n",
    "\n",
    "**`score`** evaluates the performance of the classifier on a labelled dataset by using `predict` to generate a predicted class for each message and comparing it to the true class. It returns the prediction accuracy and the confusion matrix.\n",
    "\n",
    "**Bayes’ Theorem** is applied inside the `for` loop in `predict`, where the prior probabilities are updated using the learned word likelihood probabilities to form posterior probabilities for ham and spam under the Naïve Bayes independence assumption."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961d6878",
   "metadata": {},
   "source": [
    "### 5. Train the two classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "43f6f21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ham = training[training[\"label\"] == \"ham\"][\"sms\"].tolist()\n",
    "train_spam = training[training[\"label\"] == \"spam\"][\"sms\"].tolist()\n",
    "\n",
    "nb_all = NaiveBayesForSpam()\n",
    "nb_all.train(train_ham, train_spam)\n",
    "\n",
    "nb_spam = NaiveBayesForSpam()\n",
    "nb_spam.train2(train_ham, train_spam)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa367371",
   "metadata": {},
   "source": [
    "### 6. Evaluate performance on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8b61e80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_labels = validation[\"label\"].tolist()\n",
    "validation_sms = validation[\"sms\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1ae8f5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier using train():\n",
      "Accuracy: 0.955\n",
      "Confusion matrix:\n",
      " [[844.  29.]\n",
      " [ 16. 111.]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate train()\n",
    "acc_all, conf_all = nb_all.score(validation_sms, validation_labels)\n",
    "print(\"Classifier using train():\")\n",
    "print(\"Accuracy:\", acc_all)\n",
    "print(\"Confusion matrix:\\n\", conf_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "87ad46d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier using train2():\n",
      "Accuracy: 0.963\n",
      "Confusion matrix:\n",
      " [[856.  33.]\n",
      " [  4. 107.]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate train2()\n",
    "acc_spam, conf_spam = nb_spam.score(validation_sms, validation_labels)\n",
    "print(\"Classifier using train2():\")\n",
    "print(\"Accuracy:\", acc_spam)\n",
    "print(\"Confusion matrix:\\n\", conf_spam)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ec281a",
   "metadata": {},
   "source": [
    "### 7. Explain why `train2` is faster and more accurate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f8f117",
   "metadata": {},
   "source": [
    "`train2` is faster than `train` because it applies feature selection and therefore reduces the dimensionality of the model. By keeping only words that are much more likely to appear in spam than in ham, it produces a much smaller list of `self.words`, so `predict` and `score` perform fewer posterior updates for each message. \n",
    "\n",
    "`train2` yields better accuracy because it concentrates on highly informative spam indicators and reduces the influence of common words that appear in both classes, which can add noise. This more focused feature set can generalise better to the validation set when the removed words are largely uninformative.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2175e5a",
   "metadata": {},
   "source": [
    "### 8. Count false positives and reduce them at the expense of false negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c088c532",
   "metadata": {},
   "source": [
    "False positives are ham messages classified as spam. In the confusion matrix returned by `score`, rows correspond to the predicted class and columns correspond to the true class, so false positives are the entries in row predicted spam and column true ham, which is `conf[1, 0]`. Using `train`, the number of false positives on the validation set is 16, and using `train2`, it is 4.\n",
    "\n",
    "To reduce false positives at the expense of potentially increasing false negatives, the decision threshold for predicting spam can be increased in `predict`. Instead of predicting spam when $P(\\text{spam}\\mid X) > 0.5$, require $P(\\text{spam}\\mid X) > \\tau$ for some $\\tau > 0.5$ (for example, $0.8$), which makes the classifier more conservative and reduces ham to spam errors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da87652",
   "metadata": {},
   "source": [
    "### 9. Handle missing words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4f9254",
   "metadata": {},
   "source": [
    "When no features are missing, the formula uses the full product over all $p$ features, so the index range is $i = 1,...,p$, as in the standard Naïve Bayes formula. However, when some words are missing, the corresponding features $X_j,...,X_k$ are not observed, so the formula can no longer run over all indices. Instead, the formula is restricted to the observed indices only, and so we exclude the missing indices from the range.\n",
    "\n",
    "That is, we replace the full index set $\\{1,...,p\\}$ with a set $Q$ that is defined as $\\{1,...,p\\} - \\{j,...,k\\}$, which means all  indices from 1 to $p$ except those between $j$ and $k$. The formula is then given by\n",
    "\n",
    "$$\n",
    "P(Y = C_j \\mid X_{\\text{obs}}) \\propto P(Y = C_j)\\prod_{i \\in Q} P(X_i = x_i \\mid Y = C_j).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e062a2ed",
   "metadata": {},
   "source": [
    "### 10. Modify `predict` for missing words and evalute on `test1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f3cd3f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(self, message):\n",
    "    posteriors = np.copy(self.priors)\n",
    "    msg = message.lower()\n",
    "\n",
    "    censored_words = getattr(self, \"censored_words\", set())\n",
    "\n",
    "    for i, w in enumerate(self.words):\n",
    "        if w in censored_words:\n",
    "            continue\n",
    "\n",
    "        if w in msg:\n",
    "            posteriors *= self.likelihoods[:, i]\n",
    "        else:\n",
    "            posteriors *= np.ones(2) - self.likelihoods[:, i]\n",
    "\n",
    "        posteriors = posteriors / np.linalg.norm(posteriors, ord = 1)\n",
    "\n",
    "    if posteriors[0] > 0.5:\n",
    "        return [\"ham\", posteriors[0]]\n",
    "    return [\"spam\", posteriors[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cb72bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1_labels = test1[\"label\"].tolist()\n",
    "test1_sms = test1[\"sms\"].tolist()\n",
    "censored_test1 = set(test1_list)\n",
    "\n",
    "nb_all.censored_words = censored_test1\n",
    "acc_test1_all, conf_test1_all = nb_all.score(test1_sms, test1_labels)\n",
    "print(\"Test1 classifier using train():\")\n",
    "print(\"Accuracy:\", acc_test1_all)\n",
    "print(\"Confusion matrix:\\n\", conf_test1_all)\n",
    "\n",
    "nb_spam.censored_words = censored_test1\n",
    "acc_test1_spam, conf_test1_spam = nb_spam.score(test1_sms, test1_labels)\n",
    "print(\"\\nTest1 classifier using train2():\")\n",
    "print(\"Accuracy:\", acc_test1_spam)\n",
    "print(\"Confusion matrix:\\n\", conf_test1_spam)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a015780d",
   "metadata": {},
   "source": [
    "### 11. Evaluate on `test2` and summarise the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4d205b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test2_labels = test2[\"label\"].tolist()\n",
    "test2_sms = test2[\"sms\"].tolist()\n",
    "censored_test2 = set(test2_list)\n",
    "\n",
    "nb_all.censored_words = censored_test2\n",
    "acc_test2_all, conf_test2_all = nb_all.score(test2_sms, test2_labels)\n",
    "print(\"Test2 classifier using train():\")\n",
    "print(\"Accuracy:\", acc_test2_all)\n",
    "print(\"Confusion matrix:\\n\", conf_test2_all)\n",
    "\n",
    "nb_spam.censored_words = censored_test2\n",
    "acc_test2_spam, conf_test2_spam = nb_spam.score(test2_sms, test2_labels)\n",
    "print(\"\\nTest2 classifier using train2():\")\n",
    "print(\"Accuracy:\", acc_test2_spam)\n",
    "print(\"Confusion matrix:\\n\", conf_test2_spam)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b085c3-739f-4886-88f7-56aafb1fc363",
   "metadata": {},
   "source": [
    "Both models perform better on `test1` than on `test2`, and this is because of the greater censoring in `test2` which reduces the amount of observable evidence available to update the posterior probabilities. Using `train`, the accuracy drops from 0.970 on `test1` to 0.949 on `test2`, and the confusion matrix shows more misclassifications in `test2`, especially with 57 false negatives (spam messages being predicted as ham) on `test2` compared to 28 on `test1`. Using `train2`, the accuracy also drops from 0.974 on `test1` to 0.961 on `test2`, but it still outperforms `train` and produces fewer false positives (ham messages being predicted as spam) and fewer false negatives. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
