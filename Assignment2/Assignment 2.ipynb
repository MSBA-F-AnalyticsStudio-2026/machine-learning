{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50bec8d6",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "\n",
    "- Ankita Kokkera - 06032419\n",
    "- Aria Wang - 06047688\n",
    "- Tsamara Esperanti Erwin - 06042275\n",
    "- Jean-Marc Yao - 06055972\n",
    "- Amer Mulla - 06027165"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78464983",
   "metadata": {},
   "source": [
    "Import helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e122ae51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from naive_bayes import NaiveBayesForSpam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae13653b",
   "metadata": {},
   "source": [
    "1. Load the four dataset files into Python data frames and the two list files into lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a65dfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pd.read_csv(\"training.txt\")\n",
    "validation = pd.read_csv(\"validation.txt\")\n",
    "test1 = pd.read_csv(\"test1.txt\")\n",
    "test2 = pd.read_csv(\"test2.txt\")\n",
    "\n",
    "with open(\"censored_list_test1.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    test1_list = f.read().splitlines()\n",
    "\n",
    "with open(\"censored_list_test2.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    test2_list = f.read().splitlines()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05bbb5b",
   "metadata": {},
   "source": [
    "2. Pre-process the SMS messages: Remove all punctuation and numbers from the SMS messages, and change all messages to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84aad4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [training, validation, test1, test2]:\n",
    "    df[\"sms\"] = (\n",
    "        df[\"sms\"]\n",
    "          .str.lower()\n",
    "          .str.replace(r\"[0-9]\", \"\", regex=True)\n",
    "          .str.replace(r\"[^\\w\\s]\", \"\", regex=True)\n",
    "          .str.replace(r\"\\s+\", \" \", regex=True)\n",
    "          .str.strip()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23a9b6e",
   "metadata": {},
   "source": [
    "3. Naive Bayes Classifier from code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e022fc6b",
   "metadata": {},
   "source": [
    "4. Explain the code: What is the purpose of each function? What do train and train2\n",
    "do, and what is the difference between them? Where in the code is Bayesâ€™ Theorem\n",
    "being applied?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961d6878",
   "metadata": {},
   "source": [
    "5. Use your training set to train the classifiers train and train2. Note that the interfaces\n",
    "of our classifiers require you to pass the ham and spam messages separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43f6f21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ham = training[training[\"label\"] == \"ham\"][\"sms\"].tolist()\n",
    "train_spam = training[training[\"label\"] == \"spam\"][\"sms\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2baa4f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_all = NaiveBayesForSpam()\n",
    "nb_all.train(train_ham, train_spam)\n",
    "\n",
    "nb_spam = NaiveBayesForSpam()\n",
    "nb_spam.train2(train_ham, train_spam)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa367371",
   "metadata": {},
   "source": [
    "6. Using the validation set, explore how each of the two classifiers performs out of sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8b61e80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_labels = validation[\"label\"].tolist()\n",
    "validation_sms = validation[\"sms\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1ae8f5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier using train():\n",
      "Accuracy: 0.955\n",
      "Confusion matrix:\n",
      " [[844.  29.]\n",
      " [ 16. 111.]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate train()\n",
    "acc_all, conf_all = nb_all.score(validation_sms, validation_labels)\n",
    "print(\"Classifier using train():\")\n",
    "print(\"Accuracy:\", acc_all)\n",
    "print(\"Confusion matrix:\\n\", conf_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "87ad46d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier using train2():\n",
      "Accuracy: 0.963\n",
      "Confusion matrix:\n",
      " [[856.  33.]\n",
      " [  4. 107.]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate train2()\n",
    "acc_spam, conf_spam = nb_spam.score(validation_sms, validation_labels)\n",
    "print(\"Classifier using train2():\")\n",
    "print(\"Accuracy:\", acc_spam)\n",
    "print(\"Confusion matrix:\\n\", conf_spam)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
