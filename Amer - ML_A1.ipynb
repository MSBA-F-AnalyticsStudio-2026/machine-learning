{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Wine Quality with k-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.4</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.38</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.029</td>\n",
       "      <td>31.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.98895</td>\n",
       "      <td>3.28</td>\n",
       "      <td>0.36</td>\n",
       "      <td>12.4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.7</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.29</td>\n",
       "      <td>14.9</td>\n",
       "      <td>0.053</td>\n",
       "      <td>55.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>0.99839</td>\n",
       "      <td>3.03</td>\n",
       "      <td>0.52</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.8</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.31</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.045</td>\n",
       "      <td>34.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>0.99226</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.55</td>\n",
       "      <td>12.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.4</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.19</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.084</td>\n",
       "      <td>21.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>0.99516</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.63</td>\n",
       "      <td>9.6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.1</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.031</td>\n",
       "      <td>50.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>0.98950</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.43</td>\n",
       "      <td>12.7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            5.4              0.29         0.38             1.2      0.029   \n",
       "1            6.7              0.24         0.29            14.9      0.053   \n",
       "2            6.8              0.33         0.31             7.4      0.045   \n",
       "3            6.4              0.27         0.19             2.0      0.084   \n",
       "4            6.1              0.30         0.30             2.1      0.031   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 31.0                 132.0  0.98895  3.28       0.36   \n",
       "1                 55.0                 136.0  0.99839  3.03       0.52   \n",
       "2                 34.0                 143.0  0.99226  3.06       0.55   \n",
       "3                 21.0                 191.0  0.99516  3.49       0.63   \n",
       "4                 50.0                 163.0  0.98950  3.39       0.43   \n",
       "\n",
       "   alcohol  quality  \n",
       "0     12.4        6  \n",
       "1      9.0        5  \n",
       "2     12.2        6  \n",
       "3      9.6        4  \n",
       "4     12.7        7  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df = pd.read_csv(\"/Users/apple/Desktop/IC/spring semester/ML/assignment 1/sparklingwine.csv\")\n",
    "df = pd.read_csv(\"/Users/amermulla/Desktop/Imperial/Term 2/Machine Learning/Assignments/Assignment 1/Group Assignment/sparklingwine.csv\")\n",
    "df = df.drop(columns=[\"Unnamed: 0\"], errors=\"ignore\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create the binary column `good_wine`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"good_wine\"] = (df[\"quality\"] >= 6).astype(int)  # Binary column (1 if quality >= 6, else 0)\n",
    "\n",
    "X = df.drop(columns = [\"quality\", \"good_wine\"])     # Feature matrix\n",
    "y = df[\"good_wine\"]                                 # Target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When constructing the feature matrix `X`, `quality` and `good_wine` were both dropped because:\n",
    "\n",
    "- `good_wine` is the label we want to predict, so it should not appear in `X`\n",
    "- `good_wine` is defined directly from `quality`, so keeping `quality` as a feature would artificially inflate validation and test accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Split the data into training, validation, and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X.iloc[:900]\n",
    "y_train = y.iloc[:900]\n",
    "\n",
    "X_val = X.iloc[900:1200]\n",
    "y_val = y.iloc[900:1200]\n",
    "\n",
    "X_test = X.iloc[1200:]\n",
    "y_test = y.iloc[1200:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data was split into training, validation, and test sets, without shuffling. The first 900 samples were used for training, the next 300 for validation, and the final 400 for testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Normalise the features using the Z-score transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature matrix was normalised using Z-score normalisation (via `StandardScaler`). The scaler is fit on the training set only to learn each feature’s mean and standard deviation, and the same transformation is then applied to the validation and test sets to prevent data leakage. This step is important for k-Nearest Neighbours (k-NN) because the algorithm relies on Euclidean distances, so features on larger scales would otherwise dominate the distance calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Train k-NN classifiers for k = 1, 2, …, 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_accuracies = {}\n",
    "\n",
    "for k in range(1, 101):\n",
    "    knn = KNeighborsClassifier(n_neighbors = k)\n",
    "    knn.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    y_val_pred = knn.predict(X_val_scaled)\n",
    "    acc = accuracy_score(y_val, y_val_pred)\n",
    "    \n",
    "    validation_accuracies[k] = acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A k-NN classifier was trained for each k from 1 to 100 using the training set, and each model was evaluated on the validation set using accuracy. The validation accuracy for each k was stored to select the best-performing model in the next step.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Select the best k using the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best k: [1, 9, 17]\n",
      "Selected k: 1\n",
      "Validation accuracy: 0.7567\n"
     ]
    }
   ],
   "source": [
    "best_val_acc = max(validation_accuracies.values())\n",
    "best_ks = [k for k, v in validation_accuracies.items() if v == best_val_acc]\n",
    "best_k = min(best_ks)\n",
    "\n",
    "print(f\"Best k: {best_ks}\")\n",
    "print(f\"Selected k: {best_k}\")\n",
    "print(f\"Validation accuracy: {best_val_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The maximum validation accuracy was achieved by multiple values of k (i.e., k = 1, 9, 17), so the smallest k achieving the maximum was selected.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. predicts the generalisation error using the test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.6900\n",
      "Generalisation error: 0.3100\n"
     ]
    }
   ],
   "source": [
    "# Train best model on training data\n",
    "best_knn = KNeighborsClassifier(n_neighbors = best_k)\n",
    "best_knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Test prediction\n",
    "y_test_pred = best_knn.predict(X_test_scaled)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "generalisation_error = 1 - test_accuracy\n",
    "\n",
    "print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Generalisation error: {generalisation_error:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For model training, k-NN classifiers were fitted for values of k=1 to 100 using the normalised training data. Each classifier was evaluated on the validation set, and the value of k that achieved the highest validation accuracy was selected as the best model. This approach balances model complexity, avoiding overfitting at very small values of k and underfitting at large values.\n",
    "\n",
    "The selected classifier was then evaluated on the test set to estimate the generalisation error. The test accuracy was lower than the training and validation performance, which is expected and indicates a realistic assessment of how well the model generalises to unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for First Split:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.51      0.52       132\n",
      "           1       0.76      0.78      0.77       268\n",
      "\n",
      "    accuracy                           0.69       400\n",
      "   macro avg       0.65      0.64      0.65       400\n",
      "weighted avg       0.69      0.69      0.69       400\n",
      "\n",
      "Confusion Matrix for First Split:\n",
      "[[ 67  65]\n",
      " [ 59 209]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report for First Split:\")\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "print(\"Confusion Matrix for First Split:\")\n",
    "print(confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Try a new splitting: split the data set into a training data set (first 400 samples), a\n",
    "validation data set (next 400 samples), and a test data set (last 800 samples) - again,\n",
    "please do not shuffle the data. Then redo steps 4 to 7. What is the new generalisation\n",
    "error? Explain what you find.\n",
    "How do you judge whether the classifier is well-suited for the data set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best k: 5\n",
      "New test accuracy: 0.7475\n",
      "New generalisation error: 0.2525\n"
     ]
    }
   ],
   "source": [
    "# Second split\n",
    "X_train2 = X.iloc[:400]\n",
    "y_train2 = y.iloc[:400]\n",
    "\n",
    "X_val2 = X.iloc[400:800]\n",
    "y_val2 = y.iloc[400:800]\n",
    "\n",
    "X_test2 = X.iloc[800:]\n",
    "y_test2 = y.iloc[800:]\n",
    "\n",
    "# Normalisation\n",
    "X_train2_scaled = scaler.fit_transform(X_train2)\n",
    "X_val2_scaled = scaler.transform(X_val2)\n",
    "X_test2_scaled = scaler.transform(X_test2)\n",
    "\n",
    "# Train and validate again\n",
    "validation_accuracies2 = {}\n",
    "\n",
    "for k in range(1, 101):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train2_scaled, y_train2)\n",
    "    \n",
    "    y_val_pred = knn.predict(X_val2_scaled)\n",
    "    acc = accuracy_score(y_val2, y_val_pred)\n",
    "    validation_accuracies2[k] = acc\n",
    "\n",
    "best_k2 = max(validation_accuracies2, key=validation_accuracies2.get)\n",
    "best_val_acc2 = validation_accuracies2[best_k2]\n",
    "\n",
    "# Test\n",
    "best_knn2 = KNeighborsClassifier(n_neighbors=best_k2)\n",
    "best_knn2.fit(X_train2_scaled, y_train2)\n",
    "\n",
    "y_test2_pred = best_knn2.predict(X_test2_scaled)\n",
    "test_accuracy2 = accuracy_score(y_test2, y_test2_pred)\n",
    "generalisation_error2 = 1 - test_accuracy2\n",
    "\n",
    "print(f\"New best k: {best_k2}\")\n",
    "print(f\"New test accuracy: {test_accuracy2:.4f}\")\n",
    "print(f\"New generalisation error: {generalisation_error2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new generalisation error is 0.0363 and is higher than the generalisation error before, which is 0.025. The new best k is 1, and if we change the range of k, the new best k is often the smallest value in the loop. This may because that with small training dataset, k always votes for itself, which then lead to overfitting.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.58      0.60       259\n",
      "           1       0.81      0.83      0.82       541\n",
      "\n",
      "    accuracy                           0.75       800\n",
      "   macro avg       0.71      0.70      0.71       800\n",
      "weighted avg       0.74      0.75      0.75       800\n",
      "\n",
      "Confusion Matrix:\n",
      "[[151 108]\n",
      " [ 94 447]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test2, y_test2_pred))\n",
    "\n",
    "# --- Add confusion matrix ---\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test2, y_test2_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the second experiment, the data was re-split into 400 training samples, 400 validation samples, and 800 test samples, and the same normalisation, training, and model selection procedure was repeated. The generalisation error increased compared to the first split. This is explained by the reduced size of the training set, which limits the model’s ability to learn reliable neighbourhood structures.\n",
    "\n",
    "Overall, k-NN performs reasonably well on this dataset after normalisation, but its performance is sensitive to the amount of training data and the choice of \n",
    "k. This suggests that while k-NN is suitable for this problem, its effectiveness depends strongly on data availability and proper preprocessing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
